import { BaseProvider } from '~/lib/modules/llm/base-provider';
import type { ModelInfo } from '~/lib/modules/llm/types';
import type { IProviderSetting } from '~/types/model';
import type { LanguageModelV1 } from 'ai';
import { createAzure } from '@ai-sdk/azure';
import { createOpenAI } from '@ai-sdk/openai';

/*
 * ğŸ”¥ å…¨å±€ Map ç”¨æ–¼åœ¨ fetch wrapper å’Œ onFinish ä¹‹é–“å…±äº«æ¨ç†æ‘˜è¦
 * Key: responseId (å¾ Azure response ä¸­çš„ x-request-id æˆ–ç”Ÿæˆçš„ UUID)
 * Value: { summary: string, encrypted: string }
 */
const reasoningSummaryStore = new Map<string, { summary?: string; encrypted?: string }>();

// æ¸…ç†èˆŠæ¢ç›®ï¼ˆé˜²æ­¢è¨˜æ†¶é«”æ´©æ¼ï¼‰- ä¿ç•™æœ€è¿‘ 100 å€‹
function cleanupOldReasoningSummaries() {
  if (reasoningSummaryStore.size > 100) {
    const entries = Array.from(reasoningSummaryStore.entries());

    // åˆªé™¤æœ€èˆŠçš„ 50 å€‹
    entries.slice(0, 50).forEach(([key]) => reasoningSummaryStore.delete(key));
  }
}

// å°å‡ºä¾› api.chat.ts ä½¿ç”¨
export function getReasoningSummary(requestId: string) {
  const data = reasoningSummaryStore.get(requestId);

  if (data) {
    // è®€å–å¾Œç«‹å³æ¸…ç†ä»¥ç¯€çœè¨˜æ†¶é«”
    reasoningSummaryStore.delete(requestId);
  }

  return data;
}

export default class AzureOpenAIProvider extends BaseProvider {
  name = 'AzureOpenAI';
  getApiKeyLink = 'https://portal.azure.com/#view/Microsoft_Azure_ProjectOxford/CognitiveServicesHub/~/OpenAI';

  config = {
    apiTokenKey: 'AZURE_OPENAI_API_KEY',
    baseUrlKey: 'AZURE_OPENAI_ENDPOINT',
  };

  staticModels: ModelInfo[] = [
    /*
     * âœ… Azure AI Foundry å¯¦éš›éƒ¨ç½²çš„æ¨¡å‹
     * æœ€å¾Œæ›´æ–°ï¼š2025-11-13
     * èªªæ˜ï¼šåªåŒ…å«ç”¨æˆ¶å¯¦éš›éƒ¨ç½²åœ¨ Azure AI Foundry å°ˆæ¡ˆä¸­çš„ 11 å€‹æ¨¡å‹
     */

    // ==================== DeepSeek ç³»åˆ— ====================
    {
      name: 'DeepSeek-R1',
      label: 'DeepSeek-R1 ğŸ”¥',
      provider: 'AzureOpenAI',
      maxTokenAllowed: 128000,
      maxCompletionTokens: 8192,
    },
    {
      name: 'DeepSeek-R1-0528',
      label: 'DeepSeek-R1-0528 ğŸ”¥âš¡',
      provider: 'AzureOpenAI',
      maxTokenAllowed: 128000,
      maxCompletionTokens: 8192,
    },

    // ==================== GPT-4.1 ====================
    {
      name: 'gpt-4.1',
      label: 'GPT-4.1',
      provider: 'AzureOpenAI',
      maxTokenAllowed: 1048576,
      maxCompletionTokens: 32768,
    },

    // ==================== GPT-4o ç³»åˆ— ====================
    {
      name: 'gpt-4o-realtime-preview',
      label: 'GPT-4o Realtime Preview',
      provider: 'AzureOpenAI',
      maxTokenAllowed: 128000,
      maxCompletionTokens: 16384,
    },

    // ==================== GPT-5 ç³»åˆ— ====================
    {
      name: 'gpt-5',
      label: 'GPT-5',
      provider: 'AzureOpenAI',
      maxTokenAllowed: 400000,
      maxCompletionTokens: 128000,
    },
    {
      name: 'gpt-5-codex',
      label: 'GPT-5 Codex',
      provider: 'AzureOpenAI',
      maxTokenAllowed: 400000,
      maxCompletionTokens: 128000,
    },

    // ==================== åœ–åƒç”Ÿæˆæ¨¡å‹ ====================
    {
      name: 'gpt-image-1',
      label: 'GPT Image 1',
      provider: 'AzureOpenAI',
      maxTokenAllowed: 128000,
      maxCompletionTokens: 4096,
    },

    // ==================== Grok ç³»åˆ— (xAI) ====================
    {
      name: 'grok-4-fast-reasoning',
      label: 'Grok-4 Fast Reasoning ğŸ§ ',
      provider: 'AzureOpenAI',
      maxTokenAllowed: 128000,
      maxCompletionTokens: 4096, // é™ä½ä»¥ç¬¦åˆ Azure S0 tier çš„ 50K tokens/min é™åˆ¶
    },

    // ==================== O3 ç³»åˆ— (æ¨ç†æ¨¡å‹) ====================
    {
      name: 'o3-mini',
      label: 'O3 Mini',
      provider: 'AzureOpenAI',
      maxTokenAllowed: 128000,
      maxCompletionTokens: 65000,
    },

    // ==================== Sora ç³»åˆ— (è¦–é »ç”Ÿæˆ) ====================
    {
      name: 'sora',
      label: 'Sora',
      provider: 'AzureOpenAI',
      maxTokenAllowed: 128000,
      maxCompletionTokens: 4096,
    },
    {
      name: 'sora-2',
      label: 'Sora 2',
      provider: 'AzureOpenAI',
      maxTokenAllowed: 128000,
      maxCompletionTokens: 4096,
    },
  ];

  async getDynamicModels(
    _apiKeys?: Record<string, string>,
    _settings?: IProviderSetting,
    _serverEnv?: Record<string, string>,
  ): Promise<ModelInfo[]> {
    /*
     * ğŸ” Azure AI Foundry å‹•æ…‹æ¨¡å‹ç²å–åŠŸèƒ½å·²ç¦ç”¨
     *
     * åŸå› ï¼š
     * 1. å°ˆæ¡ˆç‰¹å®šçš„éƒ¨ç½² API (/api/projects/_project/deployments) éœ€è¦ OAuth2 èªè­‰ï¼ŒAPI Key ç„¡æ³•ä½¿ç”¨
     * 2. å…¨å±€æ¨¡å‹ API (/openai/models) æœƒè¿”å›æ‰€æœ‰ 237 å€‹å¯ç”¨æ¨¡å‹ï¼Œè€Œä¸æ˜¯å°ˆæ¡ˆå¯¦éš›éƒ¨ç½²çš„æ¨¡å‹
     * 3. é€™æ˜¯ bolt.diy ç¤¾ç¾¤çš„ä¸»æµåšæ³• - ä½¿ç”¨éœæ…‹æ¨¡å‹åˆ—è¡¨
     *
     * è§£æ±ºæ–¹æ¡ˆï¼š
     * è«‹åœ¨ä¸Šæ–¹çš„ staticModels é™£åˆ—ä¸­ç¶­è­·å¯¦éš›éƒ¨ç½²çš„æ¨¡å‹åˆ—è¡¨
     * ç•¶æ‚¨åœ¨ Azure AI Foundry ä¸­æ·»åŠ æˆ–åˆªé™¤éƒ¨ç½²æ™‚ï¼Œè«‹æ‰‹å‹•æ›´æ–° staticModels é™£åˆ—
     */
    console.log('[AzureOpenAI] ä½¿ç”¨éœæ…‹æ¨¡å‹åˆ—è¡¨ï¼ˆå‹•æ…‹ç²å–å·²ç¦ç”¨ï¼‰');
    return [];
  }

  /**
   * æª¢æ¸¬ç«¯é»é¡å‹
   * Azure AI Foundry: https://{resource}.services.ai.azure.com
   * Azure OpenAI: https://{resource}.openai.azure.com
   */
  private _isAzureAIFoundry(endpoint: string): boolean {
    return (
      endpoint.includes('.services.ai.azure.com') || endpoint.includes('/openai/v1') || endpoint.includes('/models')
    );
  }

  /**
   * æª¢æ¸¬æ¨¡å‹æ˜¯å¦éœ€è¦ä½¿ç”¨ Responses API
   * gpt-5-codex åƒ…æ”¯æ´ Responses APIï¼Œä¸æ”¯æ´ Chat Completions API
   */
  private _requiresResponsesAPI(model: string): boolean {
    const responsesOnlyModels = [
      'gpt-5-codex',

      // å¯ä»¥åœ¨é€™è£¡æ·»åŠ å…¶ä»–åªæ”¯æ´ Responses API çš„æ¨¡å‹
    ];
    return responsesOnlyModels.includes(model);
  }

  getModelInstance(options: {
    model: string;
    serverEnv: Env;
    apiKeys?: Record<string, string>;
    providerSettings?: Record<string, IProviderSetting>;
  }): LanguageModelV1 {
    const { model, serverEnv, apiKeys, providerSettings } = options;

    const { apiKey, baseUrl } = this.getProviderBaseUrlAndKey({
      apiKeys,
      providerSettings: providerSettings?.[this.name],
      serverEnv: serverEnv as any,
      defaultBaseUrlKey: 'AZURE_OPENAI_ENDPOINT',
      defaultApiTokenKey: 'AZURE_OPENAI_API_KEY',
    });

    if (!apiKey) {
      throw new Error(`Missing API key for ${this.name} provider`);
    }

    // Get additional Azure-specific settings
    const resourceName = serverEnv?.AZURE_OPENAI_RESOURCE_NAME || process?.env?.AZURE_OPENAI_RESOURCE_NAME;
    const apiVersion =
      serverEnv?.AZURE_OPENAI_API_VERSION || process?.env?.AZURE_OPENAI_API_VERSION || '2025-04-01-preview';

    const deploymentName =
      serverEnv?.AZURE_OPENAI_DEPLOYMENT_NAME || process?.env?.AZURE_OPENAI_DEPLOYMENT_NAME || model;

    // æª¢æ¸¬æ˜¯å¦ç‚º Azure AI Foundry ç«¯é»
    if (baseUrl && this._isAzureAIFoundry(baseUrl)) {
      const requiresResponsesAPI = this._requiresResponsesAPI(model);
      const defaultMaxCompletionTokens = this.staticModels.find((m) => m.name === model)?.maxCompletionTokens ?? 8192;

      // Normalize base URL: ensure it ends with /v1
      let normalizedBaseUrl = baseUrl.trim().replace(/\/+$/, ''); // Remove trailing slashes

      if (!normalizedBaseUrl.endsWith('/v1')) {
        normalizedBaseUrl = `${normalizedBaseUrl}/v1`;
      }

      console.log('[AzureOpenAI] ====== Detected Azure AI Foundry endpoint ======');
      console.log('[AzureOpenAI] Original Base URL:', baseUrl);
      console.log('[AzureOpenAI] Normalized Base URL:', normalizedBaseUrl);
      console.log('[AzureOpenAI] Model:', model);
      console.log('[AzureOpenAI] Requires Responses API:', requiresResponsesAPI);
      console.log('[AzureOpenAI] Default max_completion_tokens:', defaultMaxCompletionTokens);

      /*
       * Azure AI Foundry v1 API: https://xxx.services.ai.azure.com/openai/v1/
       * ä½¿ç”¨æ¨™æº– OpenAI SDKï¼Œå®Œå…¨å…¼å®¹ OpenAI API
       */

      const openai = createOpenAI({
        apiKey,
        baseURL: normalizedBaseUrl, // ä½¿ç”¨è¦ç¯„åŒ–å¾Œçš„ base URLï¼ˆåŒ…å« /v1ï¼‰
        headers: {
          'api-key': apiKey, // Azure AI Foundry ä½¿ç”¨ api-key header
        },
        fetch: (url, init) => {
          console.log('[AzureOpenAI] ====== Making Request ======');
          console.log('[AzureOpenAI] URL:', url);
          console.log('[AzureOpenAI] Model:', model);
          console.log('[AzureOpenAI] requiresResponsesAPI:', requiresResponsesAPI);

          // Azure Responses API åƒæ•¸è½‰æ›
          if (requiresResponsesAPI && init?.body) {
            try {
              const body = JSON.parse(init.body as string);

              // ğŸ” DEBUG: è¨˜éŒ„åŸå§‹è«‹æ±‚é«”
              console.log('[AzureOpenAI] [åŸå§‹è«‹æ±‚] è«‹æ±‚é«”éµ:', Object.keys(body));
              console.log('[AzureOpenAI] [åŸå§‹è«‹æ±‚] reasoning:', JSON.stringify(body.reasoning));
              console.log('[AzureOpenAI] [åŸå§‹è«‹æ±‚] include:', JSON.stringify(body.include));

              // Azure Responses API ä½¿ç”¨ max_output_tokens è€Œé max_completion_tokens
              if (body.max_completion_tokens) {
                console.log('[AzureOpenAI] Converting max_completion_tokens to max_output_tokens for Responses API');
                body.max_output_tokens = body.max_completion_tokens;
                delete body.max_completion_tokens;
              }

              /*
               * CRITICAL FIX: Vercel AI SDK çš„ openai.responses() æ²’æœ‰æ­£ç¢ºå‚³é maxCompletionTokens
               * æˆ‘å€‘éœ€è¦å¾ URL åƒæ•¸æˆ–ä½¿ç”¨é è¨­å€¼æ‰‹å‹•æ·»åŠ  max_output_tokens
               */
              if (!body.max_output_tokens) {
                console.log(
                  `[AzureOpenAI] âš ï¸ AI SDK æœªå‚³é max_output_tokensï¼Œæ‰‹å‹•æ·»åŠ é è¨­å€¼: ${defaultMaxCompletionTokens}`,
                );
                body.max_output_tokens = defaultMaxCompletionTokens;
              }

              // ğŸ”¥ é—œéµä¿®å¾©ï¼šæ·»åŠ  reasoning summary åƒæ•¸
              if (!body.reasoning || typeof body.reasoning !== 'object') {
                console.log('[AzureOpenAI] [ä¿®å¾©] å‰µå»ºæ–°çš„ reasoning ç‰©ä»¶');
                body.reasoning = {};
              } else {
                console.log('[AzureOpenAI] [æª¢æ¸¬] reasoning ç‰©ä»¶å·²å­˜åœ¨');
              }

              // è¨­ç½® reasoning summary ç‚º auto æ¨¡å¼ï¼ˆå¯é¸å€¼ï¼š'auto' | 'detailed'ï¼‰
              if (!body.reasoning.summary) {
                console.log('[AzureOpenAI] [è¨­ç½®] reasoning.summary = "auto"');
                body.reasoning.summary = 'auto';
              } else {
                console.log(`[AzureOpenAI] [è³‡è¨Š] reasoning.summary å·²å­˜åœ¨: "${body.reasoning.summary}"ï¼Œä¿æŒä¸è®Š`);
              }

              /*
               * ğŸ”¥ ä¾ç…§å®˜æ–¹å»ºè­°ï¼ŒResponses API éœ€è¦é€é include æŒ‡å®š output item
               * é€™è£¡å¼·åˆ¶åŠ å…¥ reasoning / reasoning_summary / output_textï¼Œä»¥ç¢ºä¿å¯å–å¾—æ‘˜è¦èˆ‡åŠ å¯†å…§å®¹
               */

              const requiredIncludes = ['reasoning', 'reasoning_summary', 'output_text'];

              if (!Array.isArray(body.include)) {
                body.include = [];
              }

              for (const item of requiredIncludes) {
                if (!body.include.includes(item)) {
                  body.include.push(item);
                }
              }

              console.log('[AzureOpenAI] [è¨­ç½®] include:', JSON.stringify(body.include));

              // æ›´æ–° init.bodyï¼ˆç›´æ¥ä¿®æ”¹å±¬æ€§è€Œä¸æ˜¯é‡æ–°è³¦å€¼ï¼‰
              init.body = JSON.stringify(body);

              // ğŸ” DEBUG: è¨˜éŒ„æœ€çµ‚è«‹æ±‚é«”
              console.log('[AzureOpenAI] [æœ€çµ‚è«‹æ±‚] è«‹æ±‚é«”éµ:', Object.keys(body));
              console.log('[AzureOpenAI] [æœ€çµ‚è«‹æ±‚] reasoning:', JSON.stringify(body.reasoning));
              console.log('[AzureOpenAI] [æœ€çµ‚è«‹æ±‚] include:', JSON.stringify(body.include));
              console.log('[AzureOpenAI] [æœ€çµ‚è«‹æ±‚] Has tools:', !!body.tools);
              console.log('[AzureOpenAI] [æœ€çµ‚è«‹æ±‚] Has tool_choice:', !!body.tool_choice);
              console.log('[AzureOpenAI] [æœ€çµ‚è«‹æ±‚] Has max_output_tokens:', !!body.max_output_tokens);
              console.log('[AzureOpenAI] [æœ€çµ‚è«‹æ±‚] max_output_tokens value:', body.max_output_tokens);
            } catch (error) {
              console.log('[AzureOpenAI] âŒ ç„¡æ³•è§£æè«‹æ±‚é«”:', error);
            }
          } else if (init?.body) {
            try {
              const body = JSON.parse(init.body as string);
              console.log('[AzureOpenAI] Request body keys:', Object.keys(body));
              console.log('[AzureOpenAI] Has tools:', !!body.tools);
              console.log('[AzureOpenAI] Has tool_choice:', !!body.tool_choice);

              /*
               * ğŸ”¥ é—œéµä¿®å¾©ï¼šç‚º Chat Completions API çš„ reasoning models æ·»åŠ  stream: true
               * AI SDK çš„ generateText ä¸æœƒè‡ªå‹•æ·»åŠ ï¼Œä½† xAI çš„ reasoning models éœ€è¦ streaming
               */
              if (!body.stream) {
                console.log('[AzureOpenAI] âš ï¸ Adding stream: true for Chat Completions API');
                body.stream = true;
                init.body = JSON.stringify(body);
              }

              if (!body.max_tokens && !body.max_completion_tokens) {
                // ğŸ”¥ ç¢ºä¿ max_completion_tokens å­˜åœ¨ï¼ˆå¦‚æœæ˜¯ reasoning modelï¼‰
                console.log(`[AzureOpenAI] âš ï¸ Adding default max_completion_tokens: ${defaultMaxCompletionTokens}`);
                body.max_completion_tokens = defaultMaxCompletionTokens;
                init.body = JSON.stringify(body);
              }
            } catch {
              console.log('[AzureOpenAI] Could not parse body for logging');
            }
          }

          console.log('[AzureOpenAI] Calling fetch...');

          /*
           * ç‚º Azure Responses API è¨­å®šæ›´é•·çš„è¶…æ™‚æ™‚é–“
           * Responses API åœ¨ç”Ÿæˆå¤§å‹å°ˆæ¡ˆæ™‚éœ€è¦è¼ƒé•·çš„æ€è€ƒæ™‚é–“
           */
          const fetchPromise = fetch(url, {
            ...init,

            // @ts-ignore - undici specific options for Node.js fetch
            bodyTimeout: 300000, // 5 minutes - wait for response body chunks
            headersTimeout: 60000, // 1 minute - wait for initial headers
          });

          // æ·»åŠ è¶…æ™‚ä¿è­·
          const timeoutPromise = new Promise((_, reject) => {
            setTimeout(() => {
              reject(new Error('[AzureOpenAI] Fetch timeout after 60 seconds - no response received'));
            }, 60000);
          });

          return Promise.race([fetchPromise, timeoutPromise])
            .then(async (response: any) => {
              console.log('[AzureOpenAI] âœ… Received response!');
              console.log('[AzureOpenAI] Status:', response.status, response.statusText);

              // è¨˜éŒ„æ‰€æœ‰ response headers
              console.log('[AzureOpenAI] [å›æ‡‰ Headers]:');
              response.headers.forEach((value: string, key: string) => {
                console.log(`  ${key}: ${value}`);
              });

              /*
               * ğŸ”¥ é—œéµä¿®å¾©ï¼šç‚º Chat Completions API ä¹Ÿæå– reasoning content
               * ä½†ä½¿ç”¨ä¸åŒçš„æ–¹å¼ï¼šå¾ streaming chunks çš„ reasoning_content æ¬„ä½æå–
               */
              if (!requiresResponsesAPI) {
                console.log(
                  '[AzureOpenAI] âœ… Using Chat Completions API - will extract reasoning from streaming chunks',
                );

                if (!response.body) {
                  console.log('[AzureOpenAI] âš ï¸ Response has no body');
                  return response;
                }

                const [captureStream, clientStream] = response.body.tee();
                const newHeaders = new Headers(response.headers);
                const requestId =
                  response.headers.get('x-request-id') ||
                  response.headers.get('x-ms-request-id') ||
                  response.headers.get('apim-request-id') ||
                  crypto.randomUUID();

                newHeaders.set('x-reasoning-request-id', requestId);

                void (async () => {
                  let reasoningContent = '';

                  try {
                    const reader = captureStream.getReader();
                    const decoder = new TextDecoder();
                    let buffer = '';
                    let chunkCount = 0;

                    while (chunkCount < 200) {
                      const { done, value } = await reader.read();

                      if (done) {
                        console.log('[AzureOpenAI] ğŸ” Chat completion stream reader done');
                        break;
                      }

                      const chunkText = decoder.decode(value, { stream: true });
                      buffer += chunkText;
                      chunkCount++;

                      const lines = buffer.split('\n');
                      const incompleteLine = lines.pop() || '';
                      buffer = incompleteLine;

                      for (const line of lines) {
                        if (!line.trim() || line.startsWith(':')) {
                          continue;
                        }

                        if (line.startsWith('data: ')) {
                          const dataContent = line.substring(6).trim();

                          if (dataContent === '[DONE]') {
                            continue;
                          }

                          try {
                            const data = JSON.parse(dataContent);

                            if (data.choices && data.choices[0]?.delta?.reasoning_content) {
                              reasoningContent += data.choices[0].delta.reasoning_content;

                              if (reasoningContent.length % 500 === 0) {
                                console.log(
                                  `[AzureOpenAI] ğŸ“ Extracting reasoning_content, length: ${reasoningContent.length}`,
                                );
                              }
                            }
                          } catch (parseError) {
                            console.log('[AzureOpenAI] âš ï¸ Failed to parse SSE chunk for reasoning:', parseError);
                          }
                        }
                      }

                      if (reasoningContent.length > 4000) {
                        console.log('[AzureOpenAI] âœ… Collected sufficient reasoning content (Chat Completions)');
                        break;
                      }
                    }

                    if (reasoningContent) {
                      reasoningSummaryStore.set(requestId, {
                        summary: reasoningContent,
                        encrypted: undefined,
                      });

                      cleanupOldReasoningSummaries();

                      console.log('[AzureOpenAI] âœ… Stored reasoning summary for Chat Completions');
                    } else {
                      console.log('[AzureOpenAI] âš ï¸ No reasoning_content found in streaming response');
                    }
                  } catch (error) {
                    console.error('[AzureOpenAI] âŒ Error extracting reasoning from Chat Completions API:', error);
                  }
                })();

                return new Response(clientStream, {
                  status: response.status,
                  statusText: response.statusText,
                  headers: newHeaders,
                });
              }

              // ä»¥ä¸‹æ˜¯ Responses API çš„æ¨ç†æå–é‚è¼¯

              // å°æ–¼éä¸²æµå›æ‡‰ï¼ˆå¦‚ llmcallï¼‰ï¼Œç¹¼çºŒä½¿ç”¨åŒæ­¥ JSON è§£æ
              const contentType = response.headers.get('content-type') || '';
              const isStreamResponse = contentType.includes('text/event-stream');

              if (!isStreamResponse) {
                console.log('[AzureOpenAI] ğŸ” Non-streaming response detected, skipping SSE parsing');
                return response;
              }

              if (!response.body) {
                console.log('[AzureOpenAI] âš ï¸ Response has no body');
                return response;
              }

              const [captureStream, clientStream] = response.body.tee();
              const newHeaders = new Headers(response.headers);
              const requestId =
                response.headers.get('x-request-id') ||
                response.headers.get('x-ms-request-id') ||
                response.headers.get('apim-request-id') ||
                crypto.randomUUID();

              newHeaders.set('x-reasoning-request-id', requestId);

              void (async () => {
                try {
                  let reasoningSummary: string | undefined;
                  let reasoningEncrypted: string | undefined;

                  console.log('[AzureOpenAI] ğŸ” é–‹å§‹è®€å– SSE æµä»¥æå– reasoning...');

                  const reader = captureStream.getReader();
                  const decoder = new TextDecoder();
                  let buffer = '';
                  let chunkCount = 0;
                  let reasoningSummaryAccumulator = '';
                  let isAccumulatingReasoning = false;

                  while (chunkCount < 200 && buffer.length < 400000) {
                    const { done, value } = await reader.read();

                    if (done) {
                      console.log('[AzureOpenAI] ğŸ” SSE reader å®Œæˆ');
                      break;
                    }

                    const chunkText = decoder.decode(value, { stream: true });
                    buffer += chunkText;
                    chunkCount++;

                    if (chunkCount % 10 === 0) {
                      console.log(
                        `[AzureOpenAI] ğŸ” Chunk ${chunkCount}: é•·åº¦=${chunkText.length}, Bufferç¸½é•·åº¦=${buffer.length}`,
                      );
                    }

                    const lines = buffer.split('\n');
                    const incompleteLine = lines.pop() || '';
                    buffer = incompleteLine;

                    for (const line of lines) {
                      if (!line.trim() || line.startsWith(':')) {
                        continue;
                      }

                      if (line.startsWith('data: ')) {
                        const dataContent = line.substring(6).trim();

                        if (dataContent === '[DONE]') {
                          continue;
                        }

                        try {
                          const data = JSON.parse(dataContent);

                          if (data.type && (data.type.includes('reasoning') || data.type.includes('summary'))) {
                            console.log('[AzureOpenAI] [SSEäº‹ä»¶] ğŸ”¥', data.type);
                          }

                          if (data.type === 'response.reasoning_summary_part.added') {
                            isAccumulatingReasoning = true;
                            reasoningSummaryAccumulator = '';
                          }

                          if (data.type === 'response.reasoning_summary_text.delta' && data.delta) {
                            if (isAccumulatingReasoning) {
                              reasoningSummaryAccumulator += data.delta;
                            }
                          }

                          if (data.type === 'response.reasoning_summary_text.done') {
                            if (isAccumulatingReasoning && reasoningSummaryAccumulator) {
                              reasoningSummary = reasoningSummaryAccumulator;
                            }

                            isAccumulatingReasoning = false;
                          }

                          if (data.type === 'response.output_item.added' && data.item) {
                            const item = data.item;

                            if (item.type === 'reasoning' && item.encrypted_content) {
                              reasoningEncrypted = item.encrypted_content;
                            }

                            if (item.type === 'summary_text' && item.text) {
                              reasoningSummary = item.text;
                            }
                          }

                          if (data.type === 'response.output_item.done' && data.item?.type === 'reasoning') {
                            if (data.item?.summary && !reasoningSummary) {
                              reasoningSummary = data.item.summary;
                            }
                          }
                        } catch (parseError) {
                          console.log('[AzureOpenAI] âš ï¸ è§£æ SSE äº‹ä»¶å¤±æ•—:', parseError);
                        }
                      }
                    }

                    if (reasoningSummary && reasoningSummary.length > 1000 && chunkCount > 20) {
                      console.log('[AzureOpenAI] âœ… æ”¶é›†åˆ°è¶³å¤ æ¨ç†æ‘˜è¦ï¼Œæå‰é€€å‡º');
                      break;
                    }
                  }

                  if (reasoningSummary || reasoningEncrypted) {
                    reasoningSummaryStore.set(requestId, {
                      summary: reasoningSummary,
                      encrypted: reasoningEncrypted,
                    });

                    cleanupOldReasoningSummaries();

                    console.log('[AzureOpenAI] âœ…âœ…âœ… Reasoning è³‡æ–™å·²å­˜å„²åˆ°å…¨å±€ Map (Responses API)');
                  } else {
                    console.log('[AzureOpenAI] âš ï¸âš ï¸âš ï¸ æœªæ‰¾åˆ° reasoning æ‘˜è¦æˆ–åŠ å¯†å…§å®¹');
                  }
                } catch (readError) {
                  console.log('[AzureOpenAI] âŒ è®€å–å›æ‡‰å…§å®¹æ™‚å‡ºéŒ¯:', readError);
                  console.log('[AzureOpenAI] âŒ éŒ¯èª¤è©³æƒ…:', (readError as Error).message);
                }
              })();

              return new Response(clientStream, {
                status: response.status,
                statusText: response.statusText,
                headers: newHeaders,
              });
            })
            .catch((error) => {
              console.error('[AzureOpenAI] âŒ Fetch error:', error);
              console.error('[AzureOpenAI] Error message:', error.message);
              throw error;
            });
        },
      });

      // æ ¹æ“šæ¨¡å‹é¸æ“‡ä½¿ç”¨ Responses API æˆ– Chat Completions API
      if (requiresResponsesAPI) {
        console.log('[AzureOpenAI] Using Responses API for', model);
        return openai.responses(model) as unknown as LanguageModelV1;
      } else {
        console.log('[AzureOpenAI] Using Chat Completions API for', model);
        return openai(model) as unknown as LanguageModelV1;
      }
    } else {
      console.log('[AzureOpenAI] Using traditional Azure OpenAI endpoint');

      // å‚³çµ± Azure OpenAI é…ç½®
      const azure = createAzure({
        apiKey,

        // Use baseURL if provided (endpoint), otherwise use resourceName
        ...(baseUrl ? { baseURL: baseUrl } : { resourceName }),
        apiVersion,
      });

      // Return model instance using deployment name
      return azure(deploymentName) as unknown as LanguageModelV1;
    }
  }
}
